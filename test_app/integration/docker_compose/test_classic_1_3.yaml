version: '3'
services:
  server:
    volumes:
      - ./config.py:/fed-flow/app/config/config.py
    image: fed-flow:test
    ports:
      - "51008:51008"
    hostname: server
    deploy:
      resources:
        limits:
          cpus: '3'
        reservations:
          cpus: '3'
      restart_policy:
        condition: on-failure
    working_dir: /fed-flow/app/fl_training/runner
    entrypoint: bash -c "python3 /fed-flow/app/fl_training/runner/fed_server_run.py"
  client1:
    volumes:
      - ./config.py:/fed-flow/app/config/config.py
    image: fed-flow:test
    depends_on:
      - server
    hostname: client1
    deploy:
      resources:
        limits:
          cpus: '0.5'
        reservations:
          cpus: '0.5'
      restart_policy:
        condition: on-failure
    working_dir: /fed-flow/app/fl_training/runner
    entrypoint: bash -c "python3 /fed-flow/app/fl_training/runner/fed_client_run.py -i 0"
  client2:
    volumes:
      - ./config.py:/fed-flow/app/config/config.py
    image: fed-flow:test
    depends_on:
      - server
    hostname: client2
    deploy:
      resources:
        limits:
          cpus: '0.5'
        reservations:
          cpus: '0.5'
      restart_policy:
        condition: on-failure
    working_dir: /fed-flow/app/fl_training/runner
    entrypoint: bash -c "python3 /fed-flow/app/fl_training/runner/fed_client_run.py -i 1"
  client3:
    volumes:
      - ./config.py:/fed-flow/app/config/config.py
    image: fed-flow:test
    depends_on:
      - server
    hostname: client3
    deploy:
      resources:
        limits:
          cpus: '0.5'
        reservations:
          cpus: '0.5'
      restart_policy:
        condition: on-failure
    working_dir: /fed-flow/app/fl_training/runner
    entrypoint: bash -c "python3 /fed-flow/app/fl_training/runner/fed_client_run.py -i 2"
